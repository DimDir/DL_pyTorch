{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### В этой главе мы попробуем разобраться с тем:\n",
    "- для чего нужна нейронная сеть\n",
    "- общее устройство нейроной сети\n",
    "- и чем отличается глубокое нейронная сеть от обычной.\n",
    "\n",
    "Нейронная сеть с самом общем смысле - это ещё один алгоритм машинного обучения. И как и разные алгоритмы машинного обучения, разные типы нейронных сетей могут решать разные задачи. \n",
    "С помощью нейронных сетей можно решать, например, задачи:\n",
    "- регрессии\n",
    "- классификации (бинарной и мульти)\n",
    "- понижения разменрости\n",
    "- кластеризации\n",
    "\n",
    "Функциональной еденицей нейроной сети явялется нейрон, который принимает на входной сигнал, выполняет ряд математических операций с этим сигналом и отправляет сигнал на выход."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](img/img_1_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На изображении выше:\n",
    " + x - входной сигнла\n",
    " + w - вес или коэффициент, на который уманожаеться входной сигнал x\n",
    " + b - байес нейрона, который нужен для установки смещения\n",
    " + y - выходной сигнал нейрона (результат умножения входного сигнала x на вес w и плюс байес b)\n",
    "\n",
    "То есть выходной сигнал в данном случаем описываеться зависимостью: y = w * x + b. Это уравнение прямой, что подразумевает линейную зависимость межуд входод x и выхдом y. То есть в самом простом случае, нейроная сеть - это линейная регрессия. Эту нейроную сеть можно записать простой функцией. И через неё выразить простую линейну зависимость. Например, мы знаем, что примерно половина покупателей, заходивших в магазин покупает товар. Нам нужно рассчитать, сколько едениц товара будет продано 19 покупателям. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# Задаём прараметы модели\n",
    "w = .5    # Так как, только половина покупателей покупает товар\n",
    "b = 0     # Никакой дополнительной информации численного характера у нас нет, а значит нет и дополнитльных условий\n",
    "\n",
    "# Задаём функцию\n",
    "def n1(x):\n",
    "    return x * w + b\n",
    "\n",
    "# Рассчитываем количество купленных едениц товара\n",
    "result = n1(19)\n",
    "# Округляем результат до целого числа и выводим на экран\n",
    "print(int(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим более сложную зависимость. Случай, когда у нас есть несколько входных сигнало и один выход. Для наглядности возьмём три входных сигнала. Тогда, для каждого входного сигнала нам понадобиться свой весовой коэффициент. Уравнение, выражающее зависимость выхода от входа примет вид y = w1 * x1 + w2 * x2 + w3 * x3 + b."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](img/img_1_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, имя несколько входов мы можем расширить круг задач, для можем использовать нашу модель для рассчёта более сложных \n",
    "зависимостей. Например, у нас есть данные о клиенте банка: наличие работы, наличие текущих кредитов, семья (это входные данные).Если клиент пришёл за новым кредитом, нашай задача определить вероятность того, отдаст ли клиент новый кредит или нет. Наличие работы - это положительный фактор и можно назначить вес этому входу 0.8. Наличие невыплаченных кредитов - отрицательный фактор, поэтому и коэффициент для этого входа будет со знаком минус -0.3. Наличие семьи - положительный фактор; установим коэффициент для этого входа 0.2. Напишем функцию и посмотрим на рассчитаем несколько клиентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.7\n",
      "0.8\n",
      "-0.09999999999999998\n"
     ]
    }
   ],
   "source": [
    "# импортируем библиотеку для использования функции скалярного произведения векторов\n",
    "import numpy as np\n",
    "\n",
    "# Зададим значение весов и байес (пока, что оставим его равным нулю)\n",
    "w1 = .8\n",
    "w2 = -.3\n",
    "w3 = .2\n",
    "b = 0\n",
    "\n",
    "# Зададим данные нескольких клиентов, где числа будт соответсвовать входам x1, x2 и x3\n",
    "client1 = [1, 0, 1]\n",
    "client2 = [1, 1, 1]\n",
    "client3 = [1, 0, 0]\n",
    "client4 = [0, 1, 1]\n",
    "\n",
    "def n2(client):\n",
    "    return np.array(client).dot(np.array([w1, w2, w3])) + b\n",
    "\n",
    "# Рассчитаем вероятность для каждого из четырёх клиентов\n",
    "print(n2(client1))\n",
    "print(n2(client2))\n",
    "print(n2(client3))\n",
    "print(n2(client4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты, предсказуемы: у первого есть работа и семья и нет долгов. Поэтому вероятность возврата кредита высока.\n",
    "У второго есть и работа и семья и долги, поэтому и вероятность ниже. У третьего нет долгов, но и семьи нет - поэтому он менее надёжен. А четвёртый пока без работы и вероятность воврата вообще отрицательна. С одной стороны это даётпонять, что ему кредит давать точто не стоит, с другой - это абсолютно некоррктно с точки зрения математики. Поскольку на выходе мы хотим видеть вероятность, то давайте и помести все наши выходные значения между 0 и 1. Сделать это можно с помощью сигмоидной функции, которая выражаеться формулой:  ![image.png](img/img_1_3.png)\n",
    "Давайте просто подставим наш выходной сигнла в эту функцию в качестве аргумента. И перещитаем вероятности для каждого клиента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7310585786300049\n",
      "0.6681877721681662\n",
      "0.6899744811276125\n",
      "0.47502081252106\n"
     ]
    }
   ],
   "source": [
    "def n3(client):\n",
    "    g = np.array(client).dot(np.array([w1, w2, w3])) + b\n",
    "    return 1 / (1 + np.exp(-g))\n",
    "\n",
    "print(n3(client1))\n",
    "print(n3(client2))\n",
    "print(n3(client3))\n",
    "print(n3(client4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь наши результаты выглядят более понятно. Давайте посмотрим на то, как сейчас выглядит наш нейрон."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](img/img_1_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В действительности, функция активации это ключевой элемент нейронных сетей. Функция активации вносит элемент нелинейности в \n",
    "нейрон. Это значит, что теперь у нас есть возмжность получить нелинейные зависимости между входом и выходом. А это серьёзно \n",
    "расширяет круг задач, которые мы можем решать при помощи нейронных сетей.\n",
    "\n",
    ".* замечание: использование функций активации не единственный способ добиться нелинейности, но самый популярный.\n",
    "\n",
    "Теперь, когда есть возможность вносить нелинейность в модель есть смысл строить сети с дополнительными слоями между входом и выходом. Давайте объеденим два нейрона и посмотрим, как считается выходное значение. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](img/img_1_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выход первого слоя, то есть результат функции f(g) попадет на вход второго слоя. А конечный результат y - это результат функции f2(g). То есь, второй слой отличается от первого только новым весом w21 и новым баесом b. Давайте напишем таку сеть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer_1 = 0.6899744811276125. \n",
      "Layer_2 = 0.6184518152426012\n"
     ]
    }
   ],
   "source": [
    "# Функция описывает работу одного нейрона\n",
    "def neuron(x, w, b):\n",
    "    g = x * w + b\n",
    "    return  1 / (1 + np.exp(-g))\n",
    "\n",
    "# посчитали результат первого слоя\n",
    "layer_1 = neuron(client1[0], w=w1, b=0)\n",
    "#результат первого слоя передали в ту же функцию \"neuron\", но с новыми параметрами \"w\" и \"b\"; в качестве нового веса w21 \n",
    "#выбрали случайным образом значение 0.7, параметр b оставили без изменений равным нулю\n",
    "y = neuron(layer_1, w=.7, b=0)\n",
    "\n",
    "print(\"Layer_1 = {}. \\nLayer_2 = {}\".format(layer_1, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, что у нас есть несколько входов. Помимо этого мы хотим создать 1 скрытый слой. Тогда, нейроная сеть буед выглядеть как показано на рисунке ниже."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](img/img_1_6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь изображена полносвязная нейроная сеть. Полносвязная, означает, что сигнал от каждого нейрона предыдущего слоя предаётся каждому нейрону следующего слоя. Важное замечание: еслы мы передаём сигнал от одного нейрона к другим нейронам, то мы должны определить весовой коэффициент для каждого передаваемого сигнала к каждому нейрону. В нашем случае, мы передаём сигналы g11  и g12 после функции активации в оба нейроня второго слоя. А значит, для каждого из входящих сигналов в нейронй слоя 2 должен быть свой весовой коэффициент.\n",
    "\n",
    "Теперь у нашей сети один входной слой, один выходной слой, и один промежуточный, который в нейронных сетях называют скрытым слоем. Это и есть глубокая нейронная сеть. Всё тличие глубокой нейроной сети от обычной в том, что у глубокой нейроной сети есть скрытые слои."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
